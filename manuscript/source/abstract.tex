As Autonomous Systems (AS) become more ubiquitous in society, more responsible for our safety and our interaction with them more frequent, it is essential that they are trustworthy. Assessing the trustworthiness of AS is a mandatory challenge for the verification and development community. This will require appropriate standards and suitable metrics that may serve to objectively and comparatively judge trustworthiness of AS across the broad range of current and future applications.
%
% must extend beyond conventional verification and validation (V\&V) and safety-critical systems assurance, and now consider the the manner in which people will interface %a point where two systems, subjects meet and interact.
% and interact % communicate or be involved directly
% with AS across the broad range of current and future artificial intelligence (AI) applications. 
%
The meta-expression `trustworthiness' is examined in the context of AS capturing the relevant qualities that comprise this term in the literature. 
%
A list of challenges are presented in the form of a process that can be used as a trustworthiness assessment framework for AS. 
% We conclude that this is a really difficult problem and no one should try it.